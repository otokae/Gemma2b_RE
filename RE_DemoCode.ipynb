{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e533bb8-be9b-4dae-ba83-21eadbbc047d",
   "metadata": {},
   "source": [
    "## 1 FOR THE DEMO run these first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ed1c5-0184-4ab5-ac4b-05c5848bd3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b55ae-71b6-4d98-8c1c-e4ce63f5e1b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install SpeechRecognition\n",
    "!pip install google-cloud-texttospeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab38194b-fbf5-4632-bfd4-c5d1f69dfca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install Gradio\n",
    "!pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b0b82d9-a237-4cde-bc62-358b37166863",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97700a9fab4648ad8bc3d0a6a5a153d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kagglehub\n",
    "kagglehub.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d5d89e-9848-45d9-af11-6597bca69ee2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 FOR THE DEMO run this first to load the Fine-Tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b020e2-154b-4909-b957-b440db118081",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to model files: /home/jupyter/.cache/kagglehub/models/joelbest/gemma2b_reo/keras/default/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.model_download(\"joelbest/gemma2b_reo/keras/default\")\n",
    "\n",
    "print(\"Path to model files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d64ef57-8450-48df-b9ab-638406722ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 18:09:06.118103: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-01 18:09:06.154009: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733076546.178286    5217 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733076546.185571    5217 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-01 18:09:06.222221: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1733076550.846738    5217 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20750 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
      "  instance.compile_from_config(compile_config)\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 146 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "# run this first to load the finetuned model# import keras so it is defined for later use\n",
    "import keras\n",
    "import keras_nlp\n",
    "\n",
    "# Load the saved model in .keras format\n",
    "gemma_lm = keras.models.load_model('/home/jupyter/.cache/kagglehub/models/joelbest/gemma2b_reo/keras/default/1/my_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44dc8e71-e7ac-4ac4-9e36-465d04e59982",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# output to show the model is sucessfully loaded\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95315a6-a0b7-42e4-a615-4d9e6e0f0054",
   "metadata": {},
   "source": [
    "## 3 FOR THE DEMO run this after you load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "872b316c-d3d2-499f-a3fc-93f901ccf664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/01 18:11:45 [W] [service.go:132] login to server failed: dial tcp 44.237.78.176:7000: connect: connection refused\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FOR THE DEMO run this after you load the model\n",
    "import datetime\n",
    "import gradio as gr\n",
    "import tensorflow as tfG\n",
    "import keras\n",
    "import speech_recognition as sr\n",
    "from google.cloud import texttospeech\n",
    "\n",
    "#GW: I moved the imports to the cell above\n",
    "\n",
    "# Initialize the Text-to-Speech client\n",
    "client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "# Initialize the Speech Recognition\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Function to process Speech-to-Text\n",
    "def speech_to_text(audio):\n",
    "    try:\n",
    "        print(\"sr.AudioFile start: \", datetime.datetime.now(), \"audio=\", type(audio), audio)\n",
    "        with sr.AudioFile(audio) as source:\n",
    "            print(\"sr.AudioFile start2: \", datetime.datetime.now(), \"source=\", type(source))\n",
    "            audio_data = recognizer.record(source)\n",
    "            text = recognizer.recognize_google(audio_data)\n",
    "            print(\"sr.AudioFile end: \", datetime.datetime.now())\n",
    "            return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Sorry, I couldn't understand the audio. Please try again.\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Request error from Google STT service; {e}\"\n",
    "\n",
    "# Function to generate response from the chatbot model\n",
    "def generate_response(model: keras.Model, question: str, max_length: int = 250) -> str:\n",
    "    prompt_template = \"\"\" Role: You will use layman english to explain yourself. You will explain everything in simple terms using layman english.\n",
    "    You are a helpful real estate assistant providing support to legal matters in Ontario, \n",
    "    Canada Region; always answer the questions based on the following instructions; given the question, \n",
    "    generate an answer in 5 to 6 sentences always. For every statement in the answer, provide supporting \n",
    "    legal document or law segments from Ontario, Canada region.\n",
    "    Question:\\n{question}\\n\\nAnswer:\\n\"\"\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=question)\n",
    "    print(\"generate_response start: \", datetime.datetime.now(), \"prompt-->\", prompt,\"<--\")\n",
    "    \n",
    "    try:\n",
    "        generated_response = model.generate(prompt, max_length=max_length)\n",
    "        generated_text = generated_response.decode('utf-8') if isinstance(generated_response, bytes) else generated_response\n",
    "        answer_text = generated_text[len(prompt):].strip()\n",
    "        print(\"generate_response generated: \", datetime.datetime.now(), \"answer text-->\", answer_text, \"<--\")\n",
    "        return answer_text\n",
    "    except Exception as e:\n",
    "        return f\"⚠️ Error generating answer: {e}\"\n",
    "\n",
    "# Function to synthesize text using Google Text-to-Speech\n",
    "def synthesize_text(text):\n",
    "    input_text = texttospeech.SynthesisInput(text=text)\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"en-US\",\n",
    "        name=\"en-US-Standard-C\",\n",
    "        ssml_gender=texttospeech.SsmlVoiceGender.FEMALE\n",
    "    )\n",
    "    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
    "    \n",
    "    print(\"client synthesize_speech start: \", datetime.datetime.now())\n",
    "    response = client.synthesize_speech(\n",
    "        request={\"input\": input_text, \"voice\": voice, \"audio_config\": audio_config}\n",
    "    )\n",
    "    print(\"client synthesize_speech finished: \", datetime.datetime.now())\n",
    "    audio_file_path = \"output.mp3\"\n",
    "    with open(audio_file_path, \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "    return audio_file_path\n",
    "\n",
    "# Combined function to handle chatbot response and TTS\n",
    "def chatbot_with_tts_and_stt(audio):\n",
    "    print(\"chatbot start: \", datetime.datetime.now())\n",
    "    # Convert speech to text\n",
    "    user_input = speech_to_text(audio)\n",
    "    if not user_input.strip():\n",
    "        return \"Chatbot: I'm here to help! Please try speaking again.\", None\n",
    "    \n",
    "    # Confirm the input text\n",
    "    confirmation_message = f\"Recognized text: '{user_input}'. Is this correct? If so, proceed. If not, try again.\"\n",
    "    # Optionally, you can add a confirmation mechanism here\n",
    "    \n",
    "    # Generate chatbot response\n",
    "    answer = generate_response(gemma_lm, user_input, max_length=250)\n",
    "    \n",
    "    # Synthesize the generated text into speech\n",
    "    audio_file_path = synthesize_text(answer)\n",
    "    \n",
    "    print(\"chatbot finish: \", datetime.datetime.now())\n",
    "    return answer, audio_file_path\n",
    "\n",
    "# Create Gradio interface THIS LOOKS GOOD NEED REMOVE WATERMARK CHARACTER\n",
    "interface = gr.Interface(\n",
    "    fn=chatbot_with_tts_and_stt,\n",
    "    inputs=gr.Audio(sources=[\"microphone\"], type=\"filepath\"),\n",
    "    outputs=[gr.Textbox(), gr.Audio(autoplay=True)],\n",
    "    title=\"\"\"\n",
    "    <div style=\"display: flex; flex-direction: column; align-items: center; text-align: center; margin-bottom: 10px;\">\n",
    "        <img src=\"http://getmuggle.com/wp-content/uploads/2024/11/Logo-shrunk.png\" style=\"height: 180px; margin-bottom: -10px;\">\n",
    "        <h1 style=\"margin: 0; font-size: 24px;\">Real Estate Mate</h1>\n",
    "    </div>\n",
    "    \"\"\",\n",
    "    description=\"Speak your question and get a spoken answer.\",\n",
    "    # theme='Zarkel/IBM_Carbon_Theme'\n",
    "    theme='NoCrypt/miku'\n",
    "    # theme='shivi/calm_seafoam'\n",
    "    # theme='gstaff/xkcd'\n",
    "    # theme='NoCrypt/miku'\n",
    "    # theme='Base'\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "demo = interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668e513c-2473-4fde-818a-db148b842f47",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4 Run this code to close the interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1c4cc-6998-4d14-a3df-9aa28087ed2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interface.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b7201c-f339-4a3b-a943-98b354605787",
   "metadata": {},
   "source": [
    "## 5 Run this code if you want to clean up memory / resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9f201d-98ae-4f8b-89c6-6da676cd73e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import tensorflow as tf\n",
    "from numba import cuda\n",
    "\n",
    "def get_gpu_memory_usage():\n",
    "    \"\"\"Get the current and peak GPU memory usage.\"\"\"\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if not gpus:\n",
    "        return 0, 0  # No GPU available\n",
    "    memory_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "    return memory_info['current'], memory_info['peak']\n",
    "\n",
    "# Get GPU memory usage before cleanup\n",
    "before_memory, before_peak = get_gpu_memory_usage()\n",
    "\n",
    "# Delete any variables holding models or large objects\n",
    "try:\n",
    "    del gemma_lm  # Delete the model if it exists\n",
    "except NameError:\n",
    "    pass  # If gemma_lm doesn't exist, continue\n",
    "\n",
    "# Clear TensorFlow GPU memory\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Run garbage collection to free memory\n",
    "gc.collect()\n",
    "\n",
    "# Reset GPU memory\n",
    "try:\n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()\n",
    "except Exception as e:\n",
    "    print(f\"CUDA reset failed: {e}\")\n",
    "\n",
    "# Get GPU memory usage after cleanup\n",
    "after_memory, after_peak = get_gpu_memory_usage()\n",
    "\n",
    "# Calculate and display the memory cleared\n",
    "cleared_memory = before_memory - after_memory\n",
    "print(f\"Memory before cleanup: {before_memory / 1024**2:.2f} MB\")\n",
    "print(f\"Memory after cleanup: {after_memory / 1024**2:.2f} MB\")\n",
    "print(f\"Memory cleared: {cleared_memory / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b45ca-6b03-4965-8f6d-0a80d126bb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
